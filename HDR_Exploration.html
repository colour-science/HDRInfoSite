<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
    <meta content="text/html; charset=windows-1252"
      http-equiv="Content-Type">
    <meta http-equiv="Refresh" content="5;
      URL=http://mpto.unistudios.com/bill/HDR/">
    <title>HDR Exploration</title>
  </head>
  <body>
    <h1 align="center">Being superseeded by:</h1>
    <p align="center"><big><big><b><a
              href="http://mpto.unistudios.com/bill/HDR">http://mpto.unistudios.com/bill/HDR</a></b></big></big><br>
    </p>
    <h1 align="center"><br>
    </h1>
    <h1 align="center">"HDR Exploration"</h1>
    <div align="right"> Bill Mandel<br>
      Updated September 2013<br>
      (Updating...October 2013)<br>
      Updated November 2013<br>
      Updated March 2013<br>
    </div>
    <br>
    <br>
    Notes along way of testing available tools to process images along
    an HDR/Wide Gamut workflow.<br>
    <br>
    <h2>Background &amp; Tools needed:</h2>
    Using a variety of tools. This page walks through the setup and
    purpose of each and their dependencies.<br>
    <br>
    <i>Sony RAW Viewer</i> to export to EXR, <i>OpenEXR</i> (newer
    version 2.0.1 vs OS provided 1.7.0) including IlmBase, AMPAS tool <i>ctlrender,
























    </i>AMPAS ACES <i>ctl scripts </i>for RRT and ODT, <i>ImageMagick</i>
    to manipulate and display exr and tiff files, <i>libtiff</i> (3.9.6
    OS default), GNU <i>Octave</i> (for matlab processing), custom c++
    code to convert tiff to Y'DzDx video and back to tiff, <i>HEVC
      reference</i> encoder and decoder.<br>
    <br>
    <h3> RAW File Acquisition and Conversion:</h3>
    Sony provides a tool called "RAW Viewer" that can be used on F65
    camera MXF files to export into a variety of formats including
    OpenEXR using ACES primaries which will retain the full range of the
    shot. With this tool you can output at the native resolution
    (4096x2160) or at some lower resolutions. Typically would output at
    4096x2160 and later in PQ domain (16 bit TIFF) crop to 3840x2160 or
    output 2048x1080 and again later crop the 16 bit PQ TIFFs to
    1920x1080. It is unknown what scaler the RAW viewer uses to
    downscale 2:1 for the 2k output.<br>
    <br>
    <a href="http://www.sonycreativesoftware.com/rawviewer">http://www.sonycreativesoftware.com/rawviewer</a><br>
    <br>
    Sample F65 footage is available from Blender.org from the short
    "Tears of Steel" this footage while much of it is greenscreen has
    live action and HDR range due to an exposed lightbulb in a desklamp
    so is useful for testing with. It is recommended against downloading
    this due to the size (~20GB) but listed here as an example. All use
    of such must be properly attributed.<br>
    <br>
    Description:&nbsp; <br>
    (CC) Blender Foundation | mango.blender.org<br>
    <a
href="http://mango.blender.org/production/xiph-org-f65-raw-linear-exr-cleaned-and-finals/">http://mango.blender.org/production/xiph-org-f65-raw-linear-exr-cleaned-and-finals/</a><br>
    <br>
    Actual file: (A003C007_120507.mxf)<br>
    <a href="http://media.xiph.org/mango/raw/">http://media.xiph.org/mango/raw/</a><br>
    <br>
    <br>
    <h3>ACES Processing<br>
    </h3>
    Toolchain: OpenEXR and ctlrender with ACES ctl scripts.<br>
    <br>
    <h4> Setup:</h4>
    <h4> </h4>
    <ul>
      <li>Obtain and compile pieces of OpenEXR 2.0.1 from github. (most
        likely can use v1.7 which is typical on some OS)<br>
      </li>
      <li>Obtain and compile "ctlrender" (best to keep up with latest
        releases)<br>
      </li>
    </ul>
    <h4>OpenEXR:</h4>
    <p>Decide first if your operating system includes OpenEXR (most
      likely it does) and if the version is reasonable (e.g.
      v1.7+).&nbsp; If you choose to install the latest version watch
      dependencies because tools like ImageMagick and some image viewers
      will need to be recompiled against new libraries or they will fail
      to open EXR files.<br>
    </p>
    <p><a href="https://github.com/openexr/openexr/releases">https://github.com/openexr/openexr/releases</a><br>
    </p>
    If you choose to install OpenEXR then after you unpack the source
    build, test and install IlmBase then build, test and install
    OpenEXR. Run the test but don't worry if some tests fail due to
    computation precision. They are working in the github project to
    update this and there are notes in the project that explain some of
    the issues.<br>
    <h4>ACES work flow:</h4>
    <h5>ctlrender: </h5>
    <p>Use the development branch of ctl. All needed to build is
      ctlrender tool so that you have ability to run scripts on files
      input for this project.<br>
    </p>
    <p>
      <meta http-equiv="content-type" content="text/html;
        charset=windows-1252">
      <a href="https://github.com/ampas/CTL/releases">https://github.com/ampas/CTL/releases</a><br>
    </p>
    <h5>ACES Scripts:</h5>
    ctl scripts for RRT, ODT and other utility functions will be
    needed.&nbsp; These are useful to manipulate wide range files
    through a standard process if you do not have the ability to grade
    them or to convert output files into versions for viewing.<br>
    <p><a href="https://github.com/ampas/aces-dev/releases">https://github.com/ampas/aces-dev/releases</a><br>
    </p>
    <p><br>
    </p>
    <h4>Other Content Analysis and Display:</h4>
    <ul>
      <li>
        <h5>ImageMagick (useful to display images and for some image
          manipulation functions, can't really trust it with HDR
          material)<br>
        </h5>
      </li>
      <ul>
        <li>Make sure to uninstall, compile and re-install if you&nbsp;
          installed OpenEXR.</li>
        <li>The current dev branches of ImageMagick are adding
          capability for floating point files 16 or 32 bit. But for now
          use 16 bit TIFF or EXR until that is released.<br>
        </li>
        <li>Be careful with Octave because even 16bit EXRs cannot be
          read until ImageMagick upgrades to 32 bit capability.<br>
        </li>
      </ul>
      <li>
        <h5>Octave (like Matlab)</h5>
      </li>
      <ul>
        <li>Must have ImageMagick compiled and installed to support 16
          bit pixels. <br>
        </li>
        <ul>
          <li>--with-quantum-depth=32 needed to build! Don't forget to
            set this in the build script.<br>
          </li>
        </ul>
      </ul>
      <li>
        <h5>GnuPlot </h5>
      </li>
      <ul>
        <li>(should be default on any system) Useful for plotting PQ,
          gamma curves.<br>
        </li>
      </ul>
    </ul>
    <br>
    <h3>HEVC Toolchain: HEVC HM reference encoder/decoder <br>
    </h3>
    <br>
    Reference software hosted on a subversion server. You can mirror a
    copy and compile. <br>
    <br>
    <a href="http://hevc.hhi.fraunhofer.de/">http://hevc.hhi.fraunhofer.de/</a><br>
    <br>
    Use the 'tags' folder to pick the latest RExt version.&nbsp; While
    RExt is not used to get to a "main12" profile this version must be
    used along with a number of settings to declare it as there is not a
    single flag like "main8" or "main10"<br>
    <a href="https://hevc.hhi.fraunhofer.de/svn/svn_HEVCSoftware/tags/">https://hevc.hhi.fraunhofer.de/svn/svn_HEVCSoftware/tags/</a><br>
    <br>
    Just checkout the version you want and cd into it and compile/make.<br>
    Example:<br>
    <code>svn co
https://hevc.hhi.fraunhofer.de/svn/svn_HEVCSoftware/tags/HM-13.0+RExt-6.0/</code><br>
    <code>cd ./</code><code><code>HM-13.0+RExt-6.0</code>/build/linux<br>
    </code><code>make all_highbitdepth<br>
      &nbsp;</code><br>
    <br>
    Executable's will be in 'bin' directory of base folder.
    "TAppEncoderStatic" and "TAppDecoderStatic". The decoder runs simply
    with a .h265 essence input file and decodes out generic planar yuv
    which will need to be converted back to tiff for further analysis
    against encoder input video.<br>
    <br>
    The encoder needs both a planar yuv file and a settings file. <br>
    <br>
    <br>
    <br>
    <br>
    <h3>Custom Tools:<small><i>&nbsp; <small><small><big>[</big>updated
              to eliminate carriage of 'alpha' channel in tiffs across
              tools and ctl scripts 3-14-2014]</small></small></i></small><br>
    </h3>
    <b><a name="tiff2ydzdx"></a>Convert X'Y'Z' tiff (from PQ ODT) into
      Y'DzDx</b> for input into TAppEncoder.<br>
    <a href="http://mpto.unistudios.com/bill/HDR/dev2/tiff2ydzdx.cpp">http://mpto.unistudios.com/bill/HDR/dev2/tiff2ydzdx.cpp</a><br>
    This tool converts one input file at a time and appends onto (or
    creates) YDzDx.yuv planar 420 file. Use a second script to run a
    whole directly of files through this to create full yuv file. This
    tool performs color differencing and subsampling into Y'DzDx 4:2:0.
    Subsampling is performed by averaging 2x2 blocks.<br>
    <ul>
      <li>Command line to build: <code>g++ -O3 tiff2ydzdx.cpp -o
          tiff2ydzdx</code> <code>-ltiff&nbsp;</code></li>
      <li>Command line options: (no options it runs 12 bit Y'DzDx)</li>
      <ul>
        <li>Color formula (default is Y'DzDx) use 709 or 2020
          respectively for others</li>
        <li>Bit Depth (default is 12 bits) use B10 for 10 bits</li>
        <li>Resolution (default is 3840x2160) options are HD1920 or
          HD960. Resolution is achieved by center cutting if the image
          is bigger than the resolution.</li>
        <li>(e.g. <code>tiff2ydzdx Frame.tif</code><code> 2020 B10</code>
          would subsample and append Frame.tif using a 2020 formula and
          10 bits onto YDzDx.yuv)<br>
        </li>
      </ul>
    </ul>
    <br>
    <b>Convert Y'DzDx (from TAppDecoder) back into X'Y'Z' tiff</b> with
    data MSB justified.<br>
    <a href="http://mpto.unistudios.com/bill/HDR/dev2/ydzdx2tiff.cpp">http://mpto.unistudios.com/bill/HDR/dev2/ydzdx2tiff.cpp</a><br>
    Run this tool with a planar yuv file as input (3840x2160, 1920x1080
    and 960x540 only) and first create a directory named tifXYZ. This
    tool will dump the yuv file into that directory as MSB justified
    tiffs assuming the input data is 12 bits wide.<br>
    <ul>
      <li> Command line to build: <code>g++ -O3 ydzdx2tiff.cpp -o
          ydzdx2tiff </code><code>-ltiff </code></li>
      <li>Command line options: (no options it reverses 12 bit Y'DzDx
        back to tiff)</li>
      <ul>
        <li>Color formula (default is Y'DzDx) use 709 or 2020
          respectively for others</li>
        <li>Bit Depth (default is 12 bits) use B10 for 10 bits</li>
        <li>Resolution (default is 3840x2160) options are HD1920 or
          HD960. <br>
        </li>
        <li>(e.g. <code>ydzdx2tiff Frame.tif</code><code> 2020 B10</code>
          would subsample and append Frame.tif using a 2020 formula and
          10 bits onto YDzDx.yuv)<br>
        </li>
      </ul>
    </ul>
    <br>
    <b><a name="tifcmp"></a>Compare Tool:</b> [TBD add DE2000 analysis]<br>
    Basic tool to input two tiffs (any resolution) and perform
    difference and output that into an 8 bit tiff. (make sure no pixel
    difference is greater than 255).<br>
    <a href="http://mpto.unistudios.com/bill/HDR/dev/tifcmp.cpp">http://mpto.unistudios.com/bill/HDR/dev/tifcmp.cpp</a><br>
    To build and run:<br>
    <code>g++ -O3 tifcmp.cpp -o tifcmp</code><code> </code><code>-ltiff
      <br>
    </code><code>tifcmp XpYpZp00001.tif Frame00001.tif </code><br>
    <ul>
      <li>Command line options: <br>
      </li>
      <ul>
        <li>Bit Depth (default is 12 bits) use B10 for 10 bits or B16
          for the whole tiff files to be compared.<br>
        </li>
        <li>Default is the difference in each channel is coded into an
          8-bit sRGB TIFF. <br>
        </li>
        <li>Gain -g and offset -o options provided to allow for creation
          of a difference image centered around gray. (e.g.&nbsp;<code>
            tifcmp f1.tif f2.tif -g 2.0 -o 128</code> would double the
          difference between the files and add to 128 before writing
          into the 8-bit TIFF)<br>
        </li>
      </ul>
    </ul>
    <br>
    <br>
    <h2>Test and Analysis Workflow:</h2>
    High level steps:<br>
    <ol>
      <li>Convert RAW to ACES EXR half [or use ctlrender based process
        to get material into ACES or OCES domain]<br>
      </li>
      <li>Process AMPAS RRT [Skip is starting from OCES domain]<br>
      </li>
      <li>Process AMPAS ODT modified for PQ into X'Y'Z' 16 bit tiffs<br>
      </li>
      <li>Convert PQ tiffs into planar yuv structure file for encoder</li>
      <li>Run encoder (as main12)<br>
      </li>
      <li>Run decoder (easy no settings needed, just file out of step 5)<br>
      </li>
      <li>Convert decoder yuv output back into PQ tiff for analysis<br>
      </li>
      <li>Convert PQ tiff output into something viewable (e.g. 709
        500nit video for a bright screen)<br>
      </li>
    </ol>
    <b>Details:</b><br>
    <br>
    <big>The output of the Sony RAW viewer will be a range of frames
      exported in ACES with 16 bit half EXR numbered files. </big><br>
    <br>
    <big>Use ctlrender to process the exported F65 material into PQ
      compensated X'Y'Z'</big><br>
    <ul>
      <li>Example half EXR frame from RAW viewer (huge)<br>
      </li>
      <ul>
        <li><a
            href="http://mpto.unistudios.com/bill/HDR/dev/A003C007_12050700001.exr">http://mpto.unistudios.com/bill/HDR/dev/A003C007_12050700001.exr</a><br>
        </li>
      </ul>
      <li>RRT (from AMPAS/ACES DEV)</li>
      <li><a name="ODTPQ"></a>ODT (with PQ)</li>
      <ul>
        <li>This was done at 16 bits so that the output <a
            href="http://mpto.unistudios.com/bill/HDR/dev2/PQ.ctl">PQ </a>TIFFs




          can be used for 10, 12, and 14 bit testing. Video range is
          used (not full range).<br>
        </li>
        <ul>
          <li><a
              href="http://mpto.unistudios.com/bill/HDR/dev2/odt_PQ10k.ctl">http://mpto.unistudios.com/bill/HDR/dev2/odt_PQ10k.ctl</a>
            (10k nit PQ XYZ container)</li>
          <li><a
              href="http://mpto.unistudios.com/bill/HDR/dev2/odt_PQ10k2020.ctl">http://mpto.unistudios.com/bill/HDR/dev2/odt_PQ10k2020.ctl</a>
            (10k nit PQ Rec2020 RGB container)</li>
        </ul>
        <li>Use a script to iterate over all the frames for a test and
          create PQ TIF files. Depends on the source material the exact
          steps needed. In general from an ACES EXR it would look like a
          loop (process 8x in parallel though) of a command like the
          following<br>
        </li>
        <ul>
          <li><code>ctlrender -force -verbose -ctl
              $EDRHOME/ACES/transforms/ctl/rrt/rrt.ctl </code><code><code>-ctl




                $EDRHOME/ACES/CTL/odt_PQ10k2020.ctl TMP$c1".exr" -format
                tiff16 $PQ"2020/"$numStr".tif&nbsp;</code></code></li>
          <li><a
              href="http://mpto.unistudios.com/bill/HDR/dev2/technicolor.sh">Here




              is a full example</a> where display referred linear EXRs
            were provided that via a simple scale factor could be put
            into ACES and PQ TIFs generated.<br>
          </li>
          <ul>
          </ul>
        </ul>
      </ul>
    </ul>
    <br>
    <big><a name="source"></a>Process the X'Y'Z' data into a planar
      'yuv' style file for TAppEncoder:</big><br>
    <ul>
      <li>Run tiff2ydzdx on every input file and it will append into the
        final yuv file.</li>
      <ul>
        <li><a
            href="http://mpto.unistudios.com/bill/HDR/dev2/makeYUV.sh">Example




          </a><br>
        </li>
      </ul>
      <ul>
        <ul>
          <ul>
          </ul>
        </ul>
      </ul>
    </ul>
    <big><br>
      Run TAppEncoder with Y'DzDx.yuv file:</big><br>
    <ul>
      <li>The HM encoder has several .cfg files located in the cfg
        directory at the base of the distribution. The main10
        randomaccess one can be used for the default settings and then
        the encoder command line will adjust to put it into a "main12"
        mode.<br>
      </li>
      <li>Example command to run encoder:<br>
      </li>
      <ul>
        <li>cmd: <code>$EDRHOME/HEVC/HM/bin/TAppEncoderHighBitDepthStatic


            -c $EDRHOME/HEVC/HM/cfg/encoder_randomaccess_main10.cfg -i
            $EDRDATA/YDzDx/Technicolor/SeinePQ2020/YDzDx.yuv -wdt 1920
            -hgt 1080 -fr 25 -f $frames -fs $fs --InputBitDepth=12
            --InternalBitDepth=12 --InputChromaFormat=420 -vui 1
            --VideoFullRange=0 --ColourDescriptionPresent=1
            --ColourPrimaries=9 --TransferCharateristics=15
            --MatrixCoefficients=9 --Profile=main-RExt --Tier=main
            --Level=4.1&nbsp; -b str$qp.bin -o rec$qp.yuv<br>
            <br>
            <br>
          </code></li>
      </ul>
    </ul>
    <big>Run decoder:<br>
    </big>
    <ul>
      <li>Decoding .bin back to .yuv is straightforward:<br>
      </li>
      <li>Example command to run decoder:<br>
      </li>
      <ul>
        <li>cmd: <code>$EDRHOME/HEVC/HM/bin/TAppDecoderHighBitDepthStatic


            -b str$qp.bin -o dec$qp.yuv <br>
          </code></li>
      </ul>
    </ul>
    <big><small><code></code></small><br>
      <br>
    </big>
    <p><big><a name="DecodedSample1"></a>Convert back to tif</big> (in
      same location as str.bin)<br>
    </p>
    Reverse of process to create tif. Use ydzdx2tiff tool. <br>
    <br>
    <br>
    <p><big><big><b><a
              href="http://mpto.unistudios.com/bill/HDR/dev2/encodeHD.sh">Example




            </a></b>of entire encoding/decoding process:</big></big></p>
    <br>
    Afterward to view will need to convert every TIF file decoded (as PQ
    XYZ or PQ 2020, etc) into a form required by a particular monitor.
    Will be a loop of ODTs basically to undo the PQ compensation and
    adjust the colorimetry and apply the viewing gamma (which may be PQ)<br>
    <br>
    Here is an <a
      href="http://mpto.unistudios.com/bill/HDR/dev2/2020-2-709-500.sh">example




    </a>which puts the PQ TIF material into 709 color and through the
    709 tone curve adjusted so that 500 nits is top instead of 100. This
    gives you the ability to begin to simulate some HDR on normal bright
    monitors such as a tablet or phone. <br>
    <ul>
      <li><a
          href="http://mpto.unistudios.com/bill/HDR/dev2/INVPQ10k2020-2-XYZ.ctl">inverse




          PQ</a> with 2020 (or <a
          href="http://mpto.unistudios.com/bill/HDR/dev2/INVPQ10k-2-XYZ.ctl">inverse




          PQ </a>if XYZ)</li>
      <li><a
          href="http://mpto.unistudios.com/bill/HDR/dev2/scale10k.ctl">scale




        </a>(could have been in inverse PQ)</li>
      <li><a
          href="http://mpto.unistudios.com/bill/HDR/dev2/XYZ2ACES.ctl">XYZ




          to ACES</a> primaries<br>
      </li>
      <li><a
href="http://mpto.unistudios.com/bill/HDR/dev2/odt_rec709_full_500nits.ctl">ODT




          500 nit 709</a></li>
      <li>then use something like ImageMagick to make jpgs or pngs or
        ffmpeg/x264/x265 for .mp4s for easy viewing on your device.<br>
      </li>
    </ul>
    <br>
    <h3>Background Books and papers with good detail:</h3>
    <p><br>
    </p>
    <ul>
      <li><b>Digital Color Management: Encoding Solutions (explains RRT
          and Tone Curves)</b></li>
      <ul>
        <li><a
href="http://www.amazon.com/Digital-Color-Management-Solutions-Technology/dp/047051244X/ref=sr_1_1?ie=UTF8&amp;qid=1382672724&amp;sr=8-1&amp;keywords=digital+color+encoding+solutions">http://www.amazon.com/Digital-Color-Management-Solutions-Technology/dp/047051244X/ref=sr_1_1?ie=UTF8&amp;qid=1382672724&amp;sr=8-1&amp;keywords=digital+color+encoding+solutions</a></li>
      </ul>
      <li><b>HDR book: </b><br>
      </li>
      <ul>
        <li><a
href="http://www.amazon.com/High-Dynamic-Range-Imaging-ebook/dp/B0048EJUNM/ref=sr_1_1_title_1_kin?s=books&amp;ie=UTF8&amp;qid=1377626198&amp;sr=1-1">http://www.amazon.com/High-Dynamic-Range-Imaging-ebook/dp/B0048EJUNM/ref=sr_1_1_title_1_kin?s=books&amp;ie=UTF8&amp;qid=1377626198&amp;sr=1-1</a></li>
        <li>Chapter 4, Section 4.1 "Custom HDR Video Coding"</li>
      </ul>
      <li>Articles book based on:</li>
      <ul>
        <li><a
            href="http://pages.bangor.ac.uk/%7Eeesa0c/pdfs/mantiuk06lchdriv.pdf">http://pages.bangor.ac.uk/~eesa0c/pdfs/mantiuk06lchdriv.pdf</a></li>
        <li><a
            href="http://pages.bangor.ac.uk/%7Eeesa0c/pdfs/mantiuk07hdrvc.pdf">http://pages.bangor.ac.uk/~eesa0c/pdfs/mantiuk07hdrvc.pdf</a></li>
      </ul>
      <li>Color Gamut Mapping (likely will need this at some point)</li>
      <ul>
        <li><a
href="http://www.amazon.com/Mapping-Wiley-IS-Imaging-Science-Technology/dp/0470030321/ref=sr_1_1?ie=UTF8&amp;qid=1382672669&amp;sr=8-1&amp;keywords=color+gamut+mapping">http://www.amazon.com/Mapping-Wiley-IS-Imaging-Science-Technology/dp/0470030321/ref=sr_1_1?ie=UTF8&amp;qid=1382672669&amp;sr=8-1&amp;keywords=color+gamut+mapping</a><br>
        </li>
      </ul>
    </ul>
    <br>
  </body>
</html>
